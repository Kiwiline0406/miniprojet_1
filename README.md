# Mini-Projet ETL

Ce projet consiste à construire un pipeline de données de bout en bout en utilisant un jeu de données brut. L’objectif principal est de développer un processus efficace de transformation de données pour répondre à des besoins analytiques spécifiques. Après examination du schéma physique du jeu de données initial,  une dénormalisation sera nécessaire pour créer un schéma adapté à un DataWareHouse.

Le projet se concentre sur l’utilisation de DBT (Data Build Tool) pour orchestrer les transformations de données et la création du schéma de l’entrepôt de données, qui sera hébergé sur Amazon Redshift. En travaillant avec ces technologies, le but est d'améliorer mes performances en SQL tout en approfondissant ma compréhension du data modeling. Ce projet est une opportunité d’appliquer les concepts de modélisation des données et de renforcer mon expertise en ingénierie des données, en m'assurant que notre pipeline est optimisé pour les besoins analytiques de l’organisation.

## Objectifs 

✅ Modélisation des données : Concevoir un schéma physique du jeu de données brut et le dénormaliser pour répondre aux besoins analytiques.

✅ Intégration des données dans Redshift : Mettre en place un entrepôt de données sur Amazon Redshift et créer un cluster Redshift Serverless.

✅ Transformation des données avec DBT : Utiliser DBT pour orchestrer les transformations nécessaires et structurer les données pour l’analyse.

✅ Identification de KPI et requêtes analytiques : Définir quelques indicateurs clés de performance (KPI) avec Power BI

## Ressources

lien du jeu de données ici : https://github.com/dsteddy/jaffle_shop_data



